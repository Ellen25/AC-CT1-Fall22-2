<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />

    <title>week 7 hw</title>

   
    <link rel="stylesheet" href="style.css" />
  </head>
  <body>
    <h2>
      Real-time Sticker Adding Machine
    </h2>
    <a href="sticker.html">click here to try it</a>
    <div class="instructionDiv">
      <p class="inst">
      Instruction: keep pressing "a", "b", "c", and "d" according to the gesture instructed in the text. Press: space for classification; "S" to save the gestures; "L" to load and enjoy the generator!
      </p>
  </div>

    <div class="docs">
      <div class="examples">
        <img src="images/shot1.png">
        <img src="images/shot2.png">
        <img src="images/shot3.png">
        <img src="images/shot4.png">
      </div>

      <div class="documentation">
        <p>
          <b>Documentation & Reflection</b>
          <br>
          I think it would be interesting if the filter and stickers can be added in real-time. For instance, the stickers can be added when having synchronizing meetings through Zoom according to some gestures that the users are doing.
          I drew the stickers and used both KNN and PoseNet model so that different user can storage their own data and generate their stickers according to their gestures.
          However, sometimes it is difficult for the machine learning model to recognize similar gestures (e.g. hello and ok, which both have hand showing beside one's face).
          Therefore, this made me think that my experiment with machine learning model is still on the level of offering machine an input and it will try to provide an output that 
          fits my expectation, instead of make it generate its own creation based on the input and training materials.
        </p>
      </div>
    </div>
  </body>
</html>
